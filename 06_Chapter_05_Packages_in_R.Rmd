---
title: "06_Chapter_05_Packages in R"
author: "CTrierweiler,PGaulke"
date: "22 Juli 2019"
output: html_document
---

# Data Sets, Visualisation, and Packages in R

You already learned that R provides some built-in functions (such as `seq()`) that make your work more comfortable. However R provides also built-in data sets, that you can use for example calculation or data analysis.

One example for this is the data set mtcars.

```{r dataframe}
mtcars

data(mtcars)
class(mtcars)
mtcars
head(mtcars)
str(mtcars)

names(mtcars) 
length(mtcars)
nrow(mtcars)
```
You can find all built-in data sets here: https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html

However, apart from built-in functions and built-in data sets, there is even more to explore. In the following, we will explain how to create your individual and best R environment.

## Import Data

The actual idea of this book is that we want to enable you to analyze data in R. It will be barely possible to do so without being able to import the data you want to analyze in R. Therfore, we want to put data from other files into a data frame in order to work with it in R. With Base R, this is possibly for at least some types of files, however, for others there are some special packages to use which we wil thematize in the chapter \@ref(packages).


Generally, there are different funtion in how to read a file. The most common one is `read.table`. With this function you can read rectangular data and convert it into a data frame. For all the arguments you should check the help section `?read.table`.
Most importantly you have the arguement `file` which requires a path to find a data. If you have the file in the same folder, then the name of the file is enough. Also of high importance is the `sep` arguement which indicates the character that seperates the values between different columns.


```{r, eval=FALSE}
randomdatafile <- read.table(file="filename.txt",
                             sep=",")

``` 

For other files, R follows the logic of `read.xxx`. The xxx specifies the data format (e.g. read.csv -> .csv files)

## Data Visualisation

In the following, we will describe how you can visualize data in R. This will be limited to the base R functions, in the chapter \@ref(ggplot) you will find a way to plot data more effectively.

In order to start with this topic, at first we will look at the simplest way of plotting.

The *scatter plot* is a simple line plot in which you plot one variable against an index on the x axis Both vectors need to have exactly the same length, and of course, they need to be numeric.

The main function to use here is `plot`.

```{r simple-plots-1, out.width="25%", fig.align="center", fig.height=10, fig.cap="Creating a simple line plot.", fig.show="hold"}
revenue <- c(59000, 58000, 62000, 62000, 65000, 66000)
month <- c(01, 02, 03, 04, 05, 06)

plot(month,revenue, type ="l")
```


This looks pretty plain, so we can add some individual arguments. Show 
We now add further customization with new functions and arguments.  

- `col` adding a color (for details:(http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf)
- `lty` setting the line type (for details: http://www.sthda.com/english/wiki/line-types-in-r-lty)
- `lines` adding the plot of a vector to a previously opened plot.
- `axis` changing the axis given in its first argument with 1, 2, 3, 4 (bottom, left, top, and right)
- `at` stating for what values of the axis the labels should correspond.
- `las` stating if lables are showed horizontal or vertical
- `xlab` and `ylab` are the x and y axes labels, respectively.
- `xlim` and `ylim` set a numerical limit for the x and y axes labels, respectively, notice that a vector of length 2 is necessary for each.

The following arguements need to included in the chunk, but seperately from the actual function.
- `legend`setting a legend for the plot
- `title` setting a title for the plot

```{r simple-plots-2, out.width="25%", fig.align="center", fig.height=10, fig.cap="Creating a simple line plot.", fig.show="hold"}
revenue <- c(59000, 58000, 62000, 62000, 65000, 66000)
month <- c(01, 02, 03, 04, 05, 06)

plot(month,revenue, type ="l", col="blue",
     axes=TRUE,
     xlab = "Month",
     ylab = "Revenue"
     )
title (main="Halfyearly Plot")
```

Alternatively, you can also create barplots, histograms, boxplots, pies and other plots. For example, for a barplot you should take the function `barplot` and consider the following arguments.

- `col` for setting the colors
- `horiz` for setting the direction of the plot
- `border` setting the design of the borders of the plots
- `beside` forces side-by-side bars instead of stacking bars

```{r bar-plots, out.width="25%", fig.align="center", fig.height=7, fig.cap="Simple bar plots.", fig.show="hold"}

barplot(revenue,
        main="Monthly Revenue",
        names.arg=c("Jan","Feb","Mar","Apr","May","June"),
        border="black",
        col = "blue")


```


## Data Packages {#packages}

By installing new packages (again: Tools > Install packages) you can download additional tools for R, that gives you access to more operations, functions, and coding options. Before we introduce some major R packages that will make data science a bit easier and faster, please consider this short notice.

In case that you use anything out of an additional R package that you downloaded, you always have to include the following process when reopening the respective project.

```{r, eval=FALSE,error=TRUE}

library(package)

```
This step is necessary to reload the package and use its functions. You do not necessarily need to reinstall the whole package, but loading it from your library will definitely be required.


###MagrittR {magrittr}

Now you will meet a complete new operator for the first time that comes with the package `magrittr`. This operator is called pipe `%>%`. It provides a different way of writing operations into chunks, by which you type in your operation from left to right, instead from the outside to the inside.
From a mathematical point of view, this means`x %>% f` is equivalent to `f(x)`, `x %>% f(y)` is equivalent to `f(x, y)`, and `x %>% f %>% g %>% h`is equivalent to `h(g(f(x)))`


```{r}
require(magrittr)

somenumbers <- c(200,300,700,50,400)
sum(somenumbers)

somenumbers %>%
	sum()

sqrt(sum(somenumbers))

somenumbers %>%
	sum() %>%
	sqrt()


```

The transformation process of data frames can be processed in one operation with piping.

df_after_f <-f(df)
df_after_g <-g(df_after_f)
df_after_h <-g(df_after_g)

with piping it is

df %>%
  f %>%
  g %>%
  h
  
Furthermore, you can also use placeholders for an element that you placed before the pipe.


```{r}

#single placeholder
round(1.66666666,2)

2 %>%
	round(1.66666666, .)

#multiple placeholders
mtcars %>%
  subset(hp > 100) %>%
  aggregate(. ~ mpg,.,mean)
```


## Tidyverse {tidyverse}

Tidyverse is a large package that basically includes different packages such as `tibble`, `tidyr`,`readr`, `dplyr` and `ggplot2`. Considering all the functions and possibilties that tidyverse provides, it can be seen a subdialect of R. For a detailed overview of what tidyvere is, and what's included, see here: https://www.tidyverse.org/. Especially, the cheat sheets for ReadR and TidyR are recommendable: https://rawgit.com/rstudio/cheatsheets/master/data-import.pdf.

As a first step, please load `tidyverse`.

```{r, eval=FALSE, error=TRUE}

install.packages("tidyverse")

```

#### tibble

In a first step, we will go through the function and benefit of `tibble`. Tibble is generally a description for a data frame in tidyverse. All tibbles are data frames, but not vice versa.
Using tibble instead of regular data frames provides us benefits in terms of pace, output, informations, and simplicity.

A data set is easily created as a tibble, therefore you have to options:

```{r}

library(tidyverse)

# creating a new data set as a tibble from scratch
new_tib <- tibble(
  a = 1:5, 
  b = 5, 
  c = 20:16,
  d = 3:7
)
new_tib

# converting an existing data set into a tibble


tibmtcars <- as_tibble(mtcars)
tibmtcars

```

#### tidyr

In order to continue with `tidyr`, we are now more about how to organize a data set.
The principle of tidy data is that, that every column is a variable, every row an obersvation and every type of observation belongs in a different table. Tidyr is mainly based upon the following functions:

- `gather`
- `spread`
- `seperate`
- `unite`

To `gather`is the function that let you create key-value pairs out of multiple pairs. A large horizontal data set can therefore be converted in a vertically larger data set. This can be beneficial in order to get a clear overview on the data set.



```{r}
pricing <- tibble(type= c("B2C","B2B"),
                  productA= c(20,15),
                  productB= c(75,70),
                  productC= c(30,20),
                  productD= c(60,55),
                  productE= c(15,10)
                    )
pricing

```
Taking this example, we see that we actuall have the following three variables: type of business, product, and price. However, we have 6 columns, which obviously does not correspond to a tidy data set, in which every variable is a columnn.
Therefore, we should now tidy the data set up by considering the following logic:
- `key`, which are the messy columns (here the products)
- `value`, which are the messy values in the messy cells (here the prices)

```{r}
#The empty call is:
#gather(df, key, value, messy_col1, ..., messy_coln)

require(tidyr)

tidy_pricing <- gather(pricing,
                        key= "products",
                        value= "price",
                        productA:productE
                        ) 
tidy_pricing


```


In contrast, the function `spread` works the opposite way. Therefore, it creates a horzontally larger data set by increasing the amounts of columns according to the given variables.

```{r}
sales<- tibble(
  business= c(rep(c("B2B","B2C","Mixed"),2),"Philantrophy"),
  products= c(rep(c("product", "revenue"),3), "donation"),
  details= c("productA", 300, "productC", 240, "productB", 120, 50)
        )

sales

tidy_sales<- spread(sales, key=products, value=details)
tidy_sales

```

The function `seperate` does what its name implies, it seperates columns. The seperation can be done by different ways, you can let recycling do its work, or base it on numbers and characters.

```{r}
require(tidyverse)

# The empty call is
# separate(df, messy_var, into=c(tidy_var1, tidy_var2))

#Example for using recycling

mixedup <- tibble(info=c("Shanghai,China", "Oslo,Norway"))
mixedup

tidy_mixedup <- separate(mixedup,
                          info,
                          into= c("city", "country")
                          )

tidy_mixedup
                  
# Example for using characters

tidy_mixedup2 <- separate(mixedup,
                          info,
                          into=c("city","country"),
                          sep="a")
tidy_mixedup2

# Example for using numbers of characters

tidy_mixedup3 <- separate(mixedup,
                          info,
                          into=c("city","country"),
                          sep=5)
tidy_mixedup3


```  

Finally, the function `unite` can be simply used for the opposite. By this function you can put two columns together.

```{r}
# The empty call is:
# unite(df, tidy_var, messy_var1, messy_var2, sep="")


backtotheorigin_mixedup <- unite(tidy_mixedup, info, "city", "country", sep=",")
backtotheorigin_mixedup
```

#### readr

The package readr provides you a fast and comfortable way of using data from other data formats.
The follwing file formats are supported by readr

- read_csv(): comma separated (CSV) files
- read_tsv(): tab separated files
- read_delim(): general delimited files
- read_fwf(): fixed width files
- read_table(): tabular files where columns are separated by white-space.
- read_log(): web log files

Readr tries automatically to convert the data from the file into a tibble data set in a way, that column specification is as appropriate as possible. These are basically the main advantages, beside that it is much faster than base R imports.

For us, the most important files are .CSV files as most data sets are create in Excel-files. However, it is pretty easy to just drop the file in your project folder and then use this formula:

```{r, eval=FALSE, error=FALSE}


idea_of_a_name <- read_csv(readr_example("filename.csv"), col_types = 
  cols(
    firstcolumnname = col_double(),
    secondcolumnname = col_integer(),
    thirdcolumnname = col_character(),
    etc = col_integer(),
      )
)


```

#### deplyr

`Dplyr`is a toolset for data manipulation. The packages includes five essential function, which are the following:

- select() picks variables based on their names
- mutate() adds new variables that are functions of existing variables 
both of the two above applied on columns 

- filter() picks cases based on their values
- arrange() changes the ordering of the rows
both of the two above applied on rows

- summarise() creates a summary out of multiple data sets

Before we start with the above mentioned functions, first things first, under the following link you will find a cheat sheet: https://github.com/rstudio/cheatsheets/blob/master/data-transformation.pdf.


As you already met the piping operator `%>%`  in the chapter about magrittr(HIER REF), we will apply it within this chapter. Especially, when manipulating a data set, piping provides an easier and more efficient approach than base R. Furthermore, you can combine different functions of manipulation in one step.

```{r}
starwars
```


First we will start with the operator `select`. 


```{r}
# The empty call is (base R)
# select(df, var1, ..., varn)
# or with piping...
# df %>%
#   select(var1,..., varn)

#here a practical example with mtcars

mtcars[,c("mpg","hp")]


mtcars %>%
  select(mpg,hp)



```
Furthermore, you can select in the following ways:

```{r}
#by columns

mtcars %>%
  select(1:3)

mtcars %>%
  select(mpg:hp)

mtcars %>%
  select(-5)

mtcars %>%
  select(-hp)


```

The selection can be designed very individually by using helper arguments that describe for example a word that should be included in the variable. All helper arguments can be found in the help section:`?select`


The `mutate` function provides the possibilty to create new columns based on existing ones.

```{r}
# The empty call is (base R)
# mutate(df, new_variable = expression)
# or with piping...
# df %>%
#   mutate(new_variable = expression)

#Practical example:

mutate(mtcars, kmpg = mpg*1.60934)


mtcars %>%
  mutate(kmpg= mpg*1.60934)


```

The `filter` function is somehow similar to the `select` function but for rows. The procedure is more or less the same.

```{r}
# The empty call is (base R)
# filter(df, condition)
# or with piping...
# df %>%
#   filter(condition)

mtcars[mtcars$mpg >=20,]

mtcars %>%
  filter(mpg >= 20)

```

You find all operators for conditions in the help section: ?Comparison


The function `arrange` enables you to create a new order by considering the value of variable.

```{r}
# The empty call is (base R)
# arrange(df, var1)
# or with piping...
# df %>%
#   arrange(var1)

arrange(mtcars, desc(hp))

mtcars %>%
  arrange(desc(hp))



```


The fiveth function `summarise` provides the possibility to create a new data frame by deriving summarzing calculations from an existing data set.

The expr means a function on a vector, repsectively a variable.

```{r, eval = FALSE}
# The empty call is (base R)
# summarise(df, name = expr)
# or with piping...
# df %>%
#   summarise(name = expr)

summarise(mtcars, averagepower = mean(hp))

mtcars %>%
  summarise(averagepower = mean(hp))
```  

Again, helper function can be found in the help section `?summarise`


For some more specialised manipulation tasks you can use the function `group_by` which allows you to choose a specific group on which to apply your manipulation operation.

```{r}
mtcars %>%
  group_by(hp >200) %>%
  summarise(
    mean(mpg)
  )
# interesting result by the way

```
#### ggplot2 {#ggplot}

With the package ggplot2 you have more possiblities to visualize your data. The range in a plot will adopt automatically to new data, it will be drwan as an object instead of an image, the legend can be created automatically and the framework for plotting is unified.


Creating a scatter plot for example, works like this:

```{r, fig.show='hold', results='hide', tidy=FALSE}
library(ggplot2)
newggplot<- ggplot(mtcars, aes(x=cyl, y=hp)) + 
         geom_smooth(method=lm , se=FALSE, aes(col=cyl)) +
         geom_smooth(method=lm , se=FALSE, linetype=1, col="grey", aes(group=1)) + 
  labs(subtitle="Car Power", 
       y="Horsepower", 
       x="Cylinders", 
       title="Scatterplot", 
       caption = "Source: mtcars")

plot(newggplot)


```

The way how to write with ggplot2 might look confusing in the first moment, but there is a consistent logic behind that.


```{r}
# First you choose the data and set the mapping

Superplot <- ggplot(data=mtcars, mapping= aes(x=hp, y= mpg))
Superplot
# The you tell the general form

SP2 <- Superplot + 
      geom_line()  
SP2
# Then you have the possibility to add a variable

SP3 <- ggplot(mtcars, aes(x=hp, y= mpg, col="blue")) +
      geom_point()
SP3
# Or even attributes

SP3b <- ggplot(mtcars, aes(x=hp, y= mpg)) +
      geom_point(col="blue")
SP3b
```

By `aes` we map our data, which includes to tell x/y axis, colour, fill, size, labels, line widt, line type.

By `geom` we set the shape of our object (_point,_line,_histogram,_bar,_boxplot) and set attributes.